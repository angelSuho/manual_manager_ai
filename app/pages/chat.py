import base64, re, markdown
import torch

from config.config import IMAGE_PATTERN, client, st
from config import streamlit_config
from services.ai_service import ask_lang_graph_agent, summarize_text
from services.tts_service import generate_tts
from streamlit_current_location import current_position

streamlit_config.apply_streamlit_settings()
streamlit_config.apply_custom_css()

def convert_links(text):
    url_pattern = re.compile(r'(https?://[^\s]+)')
    return url_pattern.sub(r'<a href="\1" target="_blank">\1</a>', text)


position = current_position()
# get_geolocation í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.

if position is not None:
    # ì„¸ì…˜ì— ìœ„ì¹˜ ì €ì¥ (í‚¤ ì´ë¦„ì€ "user_location" ë“±ìœ¼ë¡œ ììœ ë¡­ê²Œ ì§€ì •)
    st.session_state["user_location"] = position

# URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (st.query_params ì‚¬ìš©)
params = st.query_params

if "car" in params:
    st.session_state.car_type = params["car"]

if "car_type" not in st.session_state:
    st.warning("ì°¨ëŸ‰ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")
    st.stop()

torch.classes.__path__ = []
if "messages" not in st.session_state:
    st.session_state.messages = []
if "audio_file" not in st.session_state:
    st.session_state.audio_file = None
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None
if "user_prompt" not in st.session_state:
    st.session_state.user_prompt = None

# -----------------------------
# ì‚¬ì´ë“œë°” ë””ìì¸ìš© CSS ì‚½ì…
# -----------------------------
st.markdown("""
<style>
/* ì‚¬ì´ë“œë°” ì „ì²´ ìŠ¤íƒ€ì¼ */
[data-testid="stSidebar"] {
    background-color: #F9F9F9 !important;
    padding: 1rem;
}

/* ë¡œê³  + íƒ€ì´í‹€ ì˜ì—­ */
.sidebar-header {
    display: flex;
    align-items: center;
    margin-bottom: 1rem;
}

.sidebar-logo {
    width: 40px;
    margin-right: 0.5rem;
}

.sidebar-title {
    font-size: 1.2rem;
    font-weight: 600;
    margin: 0;
    padding: 0;
}

/* í˜„ì¬ ì°¨ëŸ‰ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
.car-info-card {
    background-color: #ECECEC;
    padding: 15px;
    border-radius: 8px;
    margin-bottom: 1rem;
    text-align: center;
    border: 1px solid #DDD;
}
.car-info-card h3 {
    margin-top: 0;
    margin-bottom: 5px;
    color: #333;
}
.car-info-card .car-name {
    font-size: 1.1rem;
    font-weight: bold;
    color: #555;
}

/* ì…ë ¥ ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
.input-section {
    margin-top: 1rem;
    padding: 15px;
    background-color: #FFF;
    border: 1px solid #EEE;
    border-radius: 8px;
}
.input-section h4 {
    margin-top: 0;
    margin-bottom: 1rem;
    color: #333;
}

/* ë©”ì¸ í—¤ë” ìŠ¤íƒ€ì¼ (ìƒë‹¨ ê³ ì • ì˜ì—­) */
.fixed-header {
    background-color: #FFF;
    padding: 10px 0;
    border-bottom: 1px solid #DDD;
    margin-bottom: 1rem;
}

/* ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
.user-message {
    background-color: #E6F4FF;
    color: #000;
    padding: 10px;
    border-radius: 8px;
    margin: 0.5rem 0;
    max-width: 80%;
    word-wrap: break-word;
}

.bot-message {
    background-color: #F2F2F2;
    padding: 10px;
    border-radius: 8px;
    margin: 0.5rem 0;
    max-width: 80%;
    word-wrap: break-word;
}

.custom-image {
    max-width: 400px;
    border-radius: 5px;
    margin-left: auto;
}
            
.sidebar-header .sidebar-logo {
    width: 25px;   /* ì›í•˜ëŠ” ë„ˆë¹„ë¡œ ì¡°ì • */
    height: auto;
    margin-right: 0.5rem;
}

/* FAQ ì„¹ì…˜ìš© ìŠ¤íƒ€ì¼ */
.faq-container {
    padding: 10px;
}
</style>
""", unsafe_allow_html=True)

# -----------------------------
# ì‚¬ì´ë“œë°” êµ¬ì„±
# -----------------------------
with st.sidebar:
    # ë¡œê³ ì™€ íƒ€ì´í‹€
    st.markdown("""
    <div class="sidebar-header">
        <img src="https://kcc-llm.s3.ap-northeast-2.amazonaws.com/logo.png" class="sidebar-logo"/>
        <h1 class="sidebar-title">KCC User Assistant</h1>
    </div>
    """, unsafe_allow_html=True)

    # í˜„ì¬ ì°¨ëŸ‰ ì •ë³´ (ì¹´ë“œ ìŠ¤íƒ€ì¼)
    st.markdown(f"""
    <div class="car-info-card">
        <h3>í˜„ì¬ ì°¨ëŸ‰</h3>
        <div class="car-name">Mercedes-Benz {st.session_state.car_type.upper()}</div>
    </div>
    """, unsafe_allow_html=True)

    # ìŒì„±/ì´ë¯¸ì§€ ì—…ë¡œë“œ ì˜ì—­ (ì¹´ë“œ ëŠë‚Œ)
    st.markdown("""
        <h4>ìŒì„± ì…ë ¥ ë° ì´ë¯¸ì§€ ì²¨ë¶€</h4>
    """, unsafe_allow_html=True)

    st.session_state.audio_file = st.audio_input(
        "ë§ˆì´í¬ ì•„ì´ì½˜ì„ ëˆŒëŸ¬ ìŒì„±ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.",
        label_visibility="collapsed"
    )

    st.session_state.uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì§ˆë¬¸í•´ë³´ì„¸ìš”.",
        type=["png", "jpg", "jpeg"],
        label_visibility="collapsed"
    )

# -----------------------------
# ìƒë‹¨ ê³ ì • í—¤ë”
# -----------------------------
st.markdown('<div class="fixed-header"><h3 style="margin:0; padding-bottom: 7px;">KCC User Assistant</h3></div>', unsafe_allow_html=True)


def display_messages():
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.markdown(f"<div class='user-message'>{msg['content']}</div>", unsafe_allow_html=True)
            # ì´ë¯¸ì§€ê°€ ìˆì„ ê²½ìš°
            if msg.get("image"):
                st.markdown(
                    f"""
                    <div>
                        <img src='data:image/png;base64,{msg['image']}' class='custom-image' style='float:right; margin-top:8px; width:300px;'/>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
        elif msg["role"] == "assistant":
            content_html = f"<div><div class='bot-message'>{msg['content']}</div>"
            if msg.get("image") and msg["image"].startswith("http"):
                content_html += f"<br><img src='{msg['image']}' width='500' style='margin-top:8px;'/>"
            content_html += "</div>"
            st.markdown(content_html, unsafe_allow_html=True)
            
            # ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´
            if "tts" in msg and msg["tts"]:
                tts_audio_b64 = msg["tts"]
                audio_html = f"""
                <audio controls style="width:500px;">
                    <source src="data:audio/mp3;base64,{tts_audio_b64}" type="audio/mp3">
                </audio>
                """
                st.markdown(audio_html, unsafe_allow_html=True)

def handle_user_input(user_prompt=None, audio_file=None):
    if audio_file:
        transcript_result = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="ko"
        )
        user_prompt = transcript_result.text
    
    data_url = None
    if st.session_state.uploaded_image:
        image_bytes = st.session_state.uploaded_image.read()
        encoded_image = base64.b64encode(image_bytes).decode("utf-8")
        data_url = f"data:image/jpeg;base64,{encoded_image}"
    if user_prompt:
        encoded_image = None
        if st.session_state.uploaded_image:
            encoded_image = base64.b64encode(st.session_state.uploaded_image.getvalue()).decode()

        st.session_state.messages.append({
            "role": "user", 
            "content": user_prompt,
            "image": encoded_image
        })

        st.markdown(f"<div class='user-message'>{user_prompt}</div>", unsafe_allow_html=True)
        if st.session_state.get("uploaded_image"):
            st.markdown(
                f"<div style='display:flex;justify-content:flex-end;'>"
                f"<img src='data:image/png;base64,{base64.b64encode(st.session_state.uploaded_image.getvalue()).decode()}' width='300'/></div><br>",
                unsafe_allow_html=True
            )

        recent_history = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in st.session_state.messages[-10:]
            if msg["content"].strip()
        ]

        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            with st.status("ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
                try:
                    # ì´ì „ íˆìŠ¤í† ë¦¬ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€
                    resp = ask_lang_graph_agent(user_prompt, data_url, recent_history)["messages"]
                    # print(resp)
                    assistant_response = resp[-1].content if isinstance(resp, list) else resp
                    if data_url:
                        assistant_response += f"\n\n ì ê²€ì„ ìœ„í•´ ì„œë¹„ìŠ¤ ì„¼í„°ì— ë°©ë¬¸ ì˜ˆì •ì´ë¼ë©´\n ğŸ‘‰'ì„œë¹„ìŠ¤ ì„¼í„°' ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”!"
                except Exception as e:
                    st.error(f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    return
                status.update(label="ë‹µë³€ ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
        try:
            related_image = None
            match = re.search(IMAGE_PATTERN, assistant_response, flags=re.IGNORECASE)
            if match:
                related_image = match.group(0)
                assistant_response = re.sub(IMAGE_PATTERN, '', assistant_response, count=1, flags=re.IGNORECASE)
            # ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬
            assistant_response = markdown.markdown(assistant_response, extensions=['extra', 'sane_lists', 'nl2br'])

            st.markdown(f"<div class='bot-message' style='width:700px;'>{assistant_response}</div>", unsafe_allow_html=True)
            if related_image:
                st.image(related_image, width=500)
            
            # TTS ìƒì„±
            with st.spinner("TTS ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                if assistant_response.strip():
                    summary_text = summarize_text(assistant_response)
                    tts_audio_b64 = generate_tts(summary_text, lang="ko")
                else:
                    tts_audio_b64 = None

                if tts_audio_b64:
                    audio_html = f"""
                    <audio controls style="width:500px;">
                        <source src="data:audio/mp3;base64,{tts_audio_b64}" type="audio/mp3">
                    </audio>
                    """
                    st.markdown(audio_html, unsafe_allow_html=True)
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": assistant_response,
                "tts": tts_audio_b64,
                "image": related_image
            })

        except Exception as e:
            st.error(f"ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# -----------------------------
# FAQ ë²„íŠ¼ ì˜ì—­ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸)
# -----------------------------
# FAQ ì˜ì—­ì„ ê°ì‹¸ëŠ” ë°•ìŠ¤ + ì œëª© ì¶”ê°€
st.markdown("""
<div class="faq-container">
    <h4>ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)</h4>
""", unsafe_allow_html=True)

col1, col2 = st.columns(2)
with col1:
    if st.button("ê²½ê³ ë“± ì¢…ë¥˜ê°€ ë­ê°€ ìˆë‚˜ìš”?", key="faq1", use_container_width=True):
        st.session_state.user_prompt = "ê²½ê³ ë“± ì¢…ë¥˜ê°€ ë­ê°€ ìˆë‚˜ìš”?"
    if st.button("ê·¼ì²˜ì— ì„œë¹„ìŠ¤ ì„¼í„°ëŠ” ì–´ë”” ìˆë‚˜ìš”?", key="faq3", use_container_width=True):
        st.session_state.user_prompt = "ê·¼ì²˜ ì„œë¹„ìŠ¤ ì„¼í„°"

with col2:
    if st.button("íƒ€ì´ì–´ ê³µê¸°ì•• ê²½ê³ ë“±ì´ ì¼œì¡Œì„ ë•Œ ì¡°ì¹˜ëŠ”?", key="faq2", use_container_width=True):
        st.session_state.user_prompt = "íƒ€ì´ì–´ ê³µê¸°ì•• ê²½ê³ ë“±ì´ ì¼œì¡Œì„ ë•Œ ì¡°ì¹˜ëŠ”?"
    if st.button("íŒŒì›Œ ìŠ¤í‹°ì–´ë§ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼ í•˜ë‚˜ìš”?â€‹", key="faq4", use_container_width=True):
        st.session_state.user_prompt = "íŒŒì›Œ ìŠ¤í‹°ì–´ë§ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼ í•˜ë‚˜ìš”?â€‹"

# FAQ ì˜ì—­ ë‹«ê¸°
st.markdown("</div>", unsafe_allow_html=True)

# -----------------------------
# ëŒ€í™” í‘œì‹œ ë° ì±„íŒ… ì…ë ¥
# -----------------------------
display_messages()

user_prompt = st.chat_input("KCCì—ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.", key="main_chat_input")

if not user_prompt:
    user_prompt = st.session_state.user_prompt

if st.session_state.audio_file:
    handle_user_input(audio_file=st.session_state.audio_file)
    st.session_state.audio_file = None
    st.session_state.user_prompt = None
elif user_prompt:
    handle_user_input(user_prompt)
    st.session_state.user_prompt = None
